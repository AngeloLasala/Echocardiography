dataset_params:
  im_path: 'DATA'
  split: 'train'
  split_val: 'val'
  split_test: 'test'
  im_channels : 1
  im_size_h : 240  # 256
  im_size_w : 320  # 256
  name: 'eco'
  dataset_batch: 'Batch3'  # dataset batch for diffusion task
  phase: 'diastole'
  dataset_batch_regression: 'Batch2'  # dataset batch for regression task, it nust be different from dataset_batch
  trial: 'trial_23'                    # trial for regression task

diffusion_params:
  num_timesteps : 1000
  beta_start : 0.0015
  beta_end : 0.0195

ldm_params:
  down_channels: [ 128, 256, 256, 256]
  mid_channels: [ 256, 256 ]
  down_sample: [ True, True, True ]
  attn_down : [True, True, True]
  time_emb_dim: 256
  norm_channels: 32
  num_heads: 8
  conv_out_channels : 128
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  condition_config:
    condition_types: [ 'text']              # could be also ['class', 'text', 'image' ]: PUT THE DEFAULT VALUE AS 'image'
    text_condition_config:                  # here the cross attention mechanis similar to the masking, note that I renemed as 'text' becaouse it is similar to the text conditioning
      text_embed_model: 'Batch2'            # dataset batch for regression task, it nust be different from dataset_batch
      text_embed_trial: 'trial_19'          # trial for regression task:'trial_19' = swinv2 small (768)  'trial_22' = swinv2 base (1024)
      text_embed_dim: 768                   # dimension of the text embedding that the model will return, now it is the dimensione of the regressor output
      cond_drop_prob: 0.1
    image_condition_config:                 ## this is for the image conditioning - seg/heatmaps stacked on the input
      image_condition_input_channels: 6     # total number of spatial channels in the conditional heatmaps
      image_condition_output_channels: 3
      image_condition_h : 256
      image_condition_w : 256
      cond_drop_prob: 0.1
    class_condition_config :     ## this is for the class conditioning of different type of hypertrophy 
      num_classes : 4           # numebr of classes, for now it is 4
      cond_drop_prob : 0.1       # probability of dropping class labels

autoencoder_params:
  z_channels: 3
  codebook_size : 20
  down_channels : [64, 128, 256, 256]
  mid_channels : [256, 256]
  down_sample : [True, True, True]
  attn_down : [False, False, False]
  norm_channels: 32
  num_heads: 16
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  condition_config:
    condition_types: [ 'class' ]      # could be also ['class', 'text', 'image' ]: PUT THE DEFAULT VALUE AS 'image'
    text_condition_config:
      text_embed_model: 'clip'
      train_text_embed_model: False
      text_embed_dim: 512
      cond_drop_prob: 0.1
    image_condition_config:                 ## this is for the image conditioning - seg/heatmaps stacked on the input
      image_condition_input_channels: 6     # total number of spatial channels in the conditional heatmaps
      image_condition_output_channels: 3
      image_condition_h : 256
      image_condition_w : 256
      cond_drop_prob: 0.1
    class_condition_config :     ## this is for the class conditioning of different type of hypertrophy 
      num_classes : 4           # numebr of classes, for now it is 4
      cond_drop_prob : 0.1       # probability of dropping class labels


train_params:
  task_name: 'eco'
  seed : 1111
  ldm_batch_size: 8
  autoencoder_batch_size: 2
  disc_start: 2
  disc_weight: 0.5
  codebook_weight: 1
  commitment_beta: 0.2
  perceptual_weight: 1
  kl_weight: 0.000005
  ldm_epochs : 100
  autoencoder_epochs : 100
  num_samples : 25
  num_grid_rows : 5
  ldm_lr: 0.00001
  autoencoder_lr: 0.0001
  autoencoder_acc_steps : 1
  autoencoder_img_save_steps : 8
  save_frequency : 20